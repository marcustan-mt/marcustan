{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\acer\\anaconda3\\envs\\rstudio\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\acer\\anaconda3\\envs\\rstudio\\lib\\site-packages (from bs4) (4.6.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "twisted 18.7.0 requires PyHamcrest>=1.9.0, which is not installed.\n",
      "You are using pip version 10.0.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "! pip install bs4\n",
    "import urllib.request\n",
    "import requests\n",
    "import numpy as np\n",
    "from urllib.request import Request, urlopen\n",
    "import pandas as pd\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from random import randint\n",
    "import time\n",
    "import math\n",
    "import csv\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parsing webpage\n",
    "url_front = \"https://www.allforyou.sg/\"\n",
    "req = Request(url_front, headers={'User-Agent': 'Chrome//5.0'})\n",
    "page = urlopen(req)\n",
    "soup = BeautifulSoup(page)\n",
    "all_left_menu_item = soup.find('div', {'id' : 'a4u-cdd-content'})\n",
    "broad_categories = all_left_menu_item.findAll('a', {'href' : '#'})\n",
    "for i in range(0, len(broad_categories)):\n",
    "    broad_categories[i] = broad_categories[i].get_text().rstrip().lstrip()\n",
    "    broad_categories[i] = broad_categories[i].replace(\", \", \"-\")\n",
    "    broad_categories[i] = broad_categories[i].replace(\" & \", \"-\")\n",
    "    broad_categories[i] = broad_categories[i].replace(\" \", \"-\")\n",
    "    broad_categories[i] = broad_categories[i].replace(\".\", \"\")\n",
    "    broad_categories[i] = broad_categories[i].replace(\"'\", \"\")\n",
    "    broad_categories[i] = url_front + broad_categories[i]\n",
    "del broad_categories[0]\n",
    "print(broad_categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parsing to get narrower categories\n",
    "complete_narrow_category = []\n",
    "for i in range(0, len(broad_categories)):\n",
    "    req = Request(broad_categories[i], headers={'User-Agent': 'Chrome//5.0'})\n",
    "    page = urlopen(req)\n",
    "    soup = BeautifulSoup(page)\n",
    "    headers = soup.findAll('div', {'class' : 'FeaturedHeader'})\n",
    "    for x in range(0,len(headers)):\n",
    "        headers[x] = str(headers[x])\n",
    "        headers[x] = re.findall(r'<a href=\"(.*?)\" style', headers[x])[0]\n",
    "        headers[x] = url_front[0:-1] + headers[x]\n",
    "    complete_narrow_category.append(headers)\n",
    "    print(i)\n",
    "    \n",
    "# # Trying to put page number into the link\n",
    "list_with_page = list()\n",
    "for i in range(0,len(complete_narrow_category)):\n",
    "    list_to_append = list()\n",
    "    for x in range(0,len(complete_narrow_category[i])):\n",
    "        for z in range(1,4):\n",
    "            link = complete_narrow_category[i][x] + '?pagenumber=' + str(z)\n",
    "            list_to_append.append(link)\n",
    "    list_with_page.append(list_to_append)\n",
    "complete_narrow_category = list_with_page\n",
    "# print(complete_narrow_category)\n",
    "#     all_left_menu_item = soup.find('div', {'id' : 'a4u-cdd-content'})\n",
    "#     broad_categories = all_left_menu_item.findAll('a', {'href' : '#'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conducting actual webscraping\n",
    "product_details = {}\n",
    "df = pd.DataFrame()\n",
    "for i in range(0,len(complete_narrow_category)):\n",
    "    for x in range(0,len(complete_narrow_category[i])):\n",
    "        req = Request(complete_narrow_category[i][x], headers={'User-Agent': 'Chrome//5.0'})\n",
    "        page = urlopen(req)\n",
    "        soup = BeautifulSoup(page)\n",
    "        product_class = soup.findAll('div', {'class' : 'productbox thumbnail text-center'})\n",
    "        for z in range(0,len(product_class)):\n",
    "\n",
    "            #image\n",
    "            try:\n",
    "                image_link = re.findall(r'\"background:url((.*?)) ', str(product_class[z]))[0][0].replace(\"('\", \"\").replace(\"')\", \"\")\n",
    "                product_details['Image'] = image_link\n",
    "            except:\n",
    "                product_details['Image'] = 'No Image'\n",
    "            \n",
    "            #Brand and Product\n",
    "            try:\n",
    "                brand_product = product_class[z].find('span', {'itemprop' : 'name'}).get_text()\n",
    "                product_details['Brand'] = brand_product\n",
    "            except:\n",
    "                product_details['Brand'] = 'Brandless'\n",
    "            \n",
    "            #Further Details\n",
    "            try:\n",
    "                product_test_1 = product_class[z].findAll('div', {'class' : 'prod-data'})\n",
    "                prod_des = re.findall(r'&lt;br&gt;&lt;b&gt; (.*?) &lt;/b&gt;', str(product_test_1))\n",
    "                prod_des_2 = re.findall(r' &lt;/b&gt; (.*?). &lt;', str(product_test_1))\n",
    "                prod_des.append(prod_des_2[0])\n",
    "                add_info = ', '.join(prod_des)\n",
    "                product_details['Further Details'] = add_info\n",
    "            except:\n",
    "                try:\n",
    "                    #try out if the product_des_2 in the initial try-except is the main problem\n",
    "                    product_test_1 = product_class[z].findAll('div', {'class' : 'prod-data'})\n",
    "                    prod_des = re.findall(r'&lt;br&gt;&lt;b&gt; (.*?) &lt;/b&gt;', str(product_test_1))\n",
    "                    add_info = ', '.join(prod_des)\n",
    "                    product_details['Further Details'] = add_info\n",
    "                except:\n",
    "                    try:\n",
    "                        #try out if the product_des is the problem\n",
    "                        product_test_1 = product_class[z].findAll('div', {'class' : 'prod-data'})\n",
    "                        prod_des_2 = re.findall(r' &lt;/b&gt; (.*?). &lt;', str(product_test_1))\n",
    "                        product_details['Further Details'] = prod_des_2[0]\n",
    "                    except:\n",
    "                        product_details['Further Details'] = 'No Further Details'\n",
    "            if len(product_details['Further Details']) == 0:\n",
    "                product_details['Further Details'] = 'No Further Details'\n",
    "            \n",
    "            #Current Price\n",
    "            try:\n",
    "                current_price = product_class[z].find('div', {'class' : 'price'}).get_text()\n",
    "                product_details['Current Price'] = current_price\n",
    "            except:\n",
    "                product_details['Current Price'] = 'No Price'\n",
    "            \n",
    "            #Discounts & old price\n",
    "            try:\n",
    "                discount = product_class[z].find('span', {'itemprop' : 'offer'}).get_text()\n",
    "                product_details['Discount'] = discount\n",
    "                try:\n",
    "                    old_price = re.findall(r'data-oldprice=(.*?) data', str(product_class[z]))[0][1:-1]\n",
    "                    product_details['Old Price'] = old_price\n",
    "                except:\n",
    "                    product_details['Old Price'] = 'Look at new price and discount instead. There is discount on this item.'\n",
    "            except:\n",
    "                product_details['Discount'] = 'No Discount'\n",
    "                product_details['Old Price'] = 'No Discount'\n",
    "            if len(product_details['Discount']) == 1:\n",
    "                product_details['Discount'] = str(int(((float(old_price[1:]) - float(current_price[1:]))/ float(old_price[1:]))* 100)) + '% off'\n",
    "            if len(product_details['Old Price']) == 0:\n",
    "                product_details['Old Price'] = 'Refer to Discount column for the discount when purchased in a certain quantity.'\n",
    "            \n",
    "            # Stock issue\n",
    "            try:\n",
    "                out_stock = re.findall(r'data-outofstock=\"(.*?)\" data-price', str(product_class[z]))[0]\n",
    "                if out_stock == 'True':\n",
    "                    product_details['Stock'] = 'Out of Stock'\n",
    "                else:\n",
    "                    product_details['Stock'] = \"In Stock\"\n",
    "            except:\n",
    "                product_details['Stock'] = 'Error in determining stock'\n",
    "            \n",
    "            #Brand Goods Page\n",
    "            product_details['Brands Goods'] = 'No page exist for Sheng Shiong'\n",
    "            \n",
    "            #Company\n",
    "            product_details['Company'] = 'Sheng Shiong'\n",
    "            \n",
    "            #Size\n",
    "            try:\n",
    "                size = re.findall(r'span style=\"color: grey;\"&gt;(.*?)&lt;/', str(product_class[z]))[0]\n",
    "                alt_size = re.findall(r'&lt;b&gt;(.*?) &lt;/b&gt;&lt;/span&gt;', str(product_class[z]))[0]\n",
    "                product_details['Size'] = size + alt_size\n",
    "            except:\n",
    "                try:\n",
    "                    #testing if its the second line that caused the error\n",
    "                    size = re.findall(r'span style=\"color: grey;\"&gt;(.*?)&lt;/', str(product_class[z]))[0]\n",
    "                    product_details['Size'] = size \n",
    "                except:\n",
    "                    try:\n",
    "                        #testing if its the third line that caused the error\n",
    "                        alt_size = re.findall(r'&lt;b&gt;(.*?) &lt;/b&gt;&lt;/span&gt;', str(product_class[z]))[0]\n",
    "                        product_details['Size'] = alt_size\n",
    "                    except:\n",
    "                        product_details['Size'] = 'No Size'      \n",
    "            #Category Classification\n",
    "            narrow_cat = re.findall(r'https://www.allforyou.sg/(.*?)?pagenumber', str(complete_narrow_category[i][x]))[0][0:-1]\n",
    "            product_details['Narrow Category'] = narrow_cat\n",
    "            product_details['Broad Cateogry'] = broad_categories[i].split('https://www.allforyou.sg/')[-1]\n",
    "            df = df.append(product_details, ignore_index = True)\n",
    "        print(x)\n",
    "    print(i)\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_class = soup.findAll('div', {'class' : 'productbox thumbnail text-center'})\n",
    "# print(product_class[0])\n",
    "\n",
    "#discount\n",
    "print(product_class[0].find('span', {'itemprop' : 'offer'}).get_text())\n",
    "\n",
    "#image link\n",
    "image_link = re.findall(r'\"background:url((.*?)) ', str(product_class[0]))[0][0].replace(\"('\", \"\").replace(\"')\", \"\")\n",
    "print(image_link)\n",
    "\n",
    "#Brand and product\n",
    "print(product_class[0].find('span', {'itemprop' : 'name'}).get_text())\n",
    "\n",
    "#Further details\n",
    "product_test = soup.findAll('div', {'class' : 'productbox thumbnail text-center'})\n",
    "product_test_1 = product_test[17].findAll('div', {'class' : 'prod-data'})\n",
    "prod_des = re.findall(r'&lt;br&gt;&lt;b&gt; (.*?) &lt;/b&gt;', str(product_test_1))\n",
    "prod_des_2 = re.findall(r' &lt;/b&gt; (.*?). &lt;', str(product_test_1))\n",
    "prod_des.append(prod_des_2[0])\n",
    "add_info = ', '.join(prod_des)\n",
    "print(add_info)\n",
    "\n",
    "#Current Price\n",
    "print(product_class[0].find('div', {'class' : 'price'}).get_text())\n",
    "\n",
    "#Old Price\n",
    "old_price = re.findall(r'data-oldprice=(.*?) data', str(product_class[0]))[0][1:-1]\n",
    "print(old_price)\n",
    "#Discount without old price\n",
    "##use dictionary length to direct people to look at dscount price instead\n",
    "\n",
    "#instock or not\n",
    "out_stock = re.findall(r'data-outofstock=\"(.*?)\" data-price', str(product_test[2]))[0]\n",
    "if out_stock == 'True':\n",
    "    print('Out of Stock')\n",
    "else:\n",
    "    print('In Stock')\n",
    "    \n",
    "#Brand Goods\n",
    "print('No page to consolidate brand goods')\n",
    "\n",
    "#Company\n",
    "print('Sheng Shiong')\n",
    "\n",
    "#Size\n",
    "size = re.findall(r'span style=\"color: grey;\"&gt;(.*?)&lt;/', str(product_test[7]))[0]\n",
    "print(size)\n",
    "#alt size\n",
    "alt_size = re.findall(r'&lt;b&gt;(.*?) &lt;/b&gt;&lt;/span&gt;', str(product_test[17]))[0]\n",
    "print(alt_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_front = \"https://www.allforyou.sg/baking-ingredients\"\n",
    "req = Request(url_front, headers={'User-Agent': 'Chrome//5.0'})\n",
    "page = urlopen(req)\n",
    "soup = BeautifulSoup(page)\n",
    "product_test = soup.findAll('div', {'class' : 'productbox thumbnail text-center'})\n",
    "print(product_test[39])\n",
    "old_price = re.findall(r'data-oldprice=(.*?) data', str(product_test[39]))[0][1:-1]\n",
    "print(old_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out of stock\n"
     ]
    }
   ],
   "source": [
    "url_front = \"https://www.allforyou.sg/wholegrain-glutinous-rice\"\n",
    "req = Request(url_front, headers={'User-Agent': 'Chrome//5.0'})\n",
    "page = urlopen(req)\n",
    "soup = BeautifulSoup(page)\n",
    "product_test = soup.findAll('div', {'class' : 'productbox thumbnail text-center'})\n",
    "# print(product_test[2])\n",
    "out_stock = re.findall(r'data-outofstock=\"(.*?)\" data-price', str(product_test[2]))[0]\n",
    "if out_stock == 'True':\n",
    "    print('Out of Stock')\n",
    "else:\n",
    "    print('In Stock')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #trial for old price\n",
    "# dit = {}\n",
    "# dit['LOL'] = 'price'\n",
    "# if len(dit['LOL']) >= 1:\n",
    "#     print('not empty')\n",
    "print(len(product_details['Old Price']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)\n",
    "df.to_csv('Sheng Shiong Scrape.csv', sep =',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
